import streamlit as st 
import chat

st.set_page_config(page_title='Agentic Workflow', page_icon=None, layout="centered", initial_sidebar_state="auto", menu_items=None)

mode_descriptions = {
    "ì¼ìƒì ì¸ ëŒ€í™”": [
        "ëŒ€í™”ì´ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì±—ë´‡ê³¼ ì¼ìƒì˜ ëŒ€í™”ë¥¼ í¸ì•ˆíˆ ì¦ê¸¸ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    ],
    "RAG": [
        "Bedrock Knowledge Baseë¥¼ ì´ìš©í•´ êµ¬í˜„í•œ RAGë¡œ í•„ìš”í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    ],
    "Agent (Tool Use)": [
        "Tool Use ë°©ì‹ì˜ Workflowë¥¼ ìˆ˜í–‰í•˜ëŠ” Agentë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œëŠ” ë‚ ì”¨, ì‹œê°„, ë„ì„œì¶”ì²œ, RAG, ì¸í„°ë„· ê²€ìƒ‰ì„ ì œê³µí•©ë‹ˆë‹¤."
    ],
    "Agent (Reflection)": [
        "Reflection Workflowë¥¼ ìˆ˜í–‰í•˜ëŠ” Agent êµ¬í˜„í•©ë‹ˆë‹¤."
    ],
    "Agent (Planning)": [
        "Planning Workflowë¥¼ ìˆ˜í–‰í•˜ëŠ” Agent êµ¬í˜„í•©ë‹ˆë‹¤."
    ],
    "Agent (Multi-agent Collaboration)": [
        "Planning/Reflection agentë“¤ì„ ì´ìš©í•˜ì—¬ Multi-agent Collaboration Workflowì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ Reflection agentë“¤ì€ ë³‘ë ¬ì²˜ë¦¬í•˜ì—¬ ìˆ˜í–‰ì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤."
    ]
}

with st.sidebar:
    st.title("ğŸ”® Menu")
    
    st.markdown(
        "Amazon Bedrockì„ ì´ìš©í•´ ë‹¤ì–‘í•œ í˜•íƒœì˜ ëŒ€í™”ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤." 
        "ì—¬ê¸°ì—ì„œëŠ” ì¼ìƒì ì¸ ëŒ€í™”ì™€ ê°ì¢… íˆ´ì„ ì´ìš©í•´ Agentë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤." 
        "ë˜í•œ ë²ˆì—­ì´ë‚˜ ë¬¸ë²• í™•ì¸ê³¼ ê°™ì€ ìš©ë„ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        "ì£¼ìš” ì½”ë“œëŠ” LangChainê³¼ LangGraphë¥¼ ì´ìš©í•´ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
        "ìƒì„¸í•œ ì½”ë“œëŠ” [Github](https://github.com/kyopark2014/langgraph-nova)ì„ ì°¸ì¡°í•˜ì„¸ìš”."
    )

    st.subheader("ğŸ± ëŒ€í™” í˜•íƒœ")
    
    # radio selection
    mode = st.radio(
        label="ì›í•˜ëŠ” ëŒ€í™” í˜•íƒœë¥¼ ì„ íƒí•˜ì„¸ìš”. ",options=["ì¼ìƒì ì¸ ëŒ€í™”", "RAG", "Agent (Tool Use)", "Agent (Reflection)", "Agent (Planning)", "Agent (Multi-agent Collaboration)"], index=0
    )   
    st.info(mode_descriptions[mode][0])    
    # print('mode: ', mode)

    # model selection box
    modelName = st.selectbox(
        'ğŸ–Šï¸ ì‚¬ìš© ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”',
        ('Nova Pro', 'Nova Lite', 'Claude 3.5 Sonnet', 'Claude 3.0 Sonnet', 'Claude 3.5 Haiku')
    )

    # debug checkbox
    select_debugMode = st.checkbox('Debug Mode', value=True)
    debugMode = 'Enable' if select_debugMode else 'Disable'
    #print('debugMode: ', debugMode)

    # multi region check box
    select_multiRegion = st.checkbox('Multi Region', value=False)
    multiRegion = 'Enable' if select_multiRegion else 'Disable'
    #print('multiRegion: ', multiRegion)

    # chart checkbox 
    selected_chart = st.checkbox('Chart', value=True)
    chart = 'Enable' if selected_chart else 'Disable'
    #print('chart: ', chart)

    chat.update(modelName, debugMode, multiRegion)

    st.subheader("ğŸ“‹ ë¬¸ì„œ ì—…ë¡œë“œ")
    # print('fileId: ', chat.fileId)
    uploaded_file = st.file_uploader("RAGë¥¼ ìœ„í•œ íŒŒì¼ì„ ì„ íƒí•©ë‹ˆë‹¤.", type=["pdf", "txt", "py", "md", "csv", "json"], key=chat.fileId)

    # code interpreter checkbox
    select_csat_evaluator = st.checkbox('CSAT evaluator', value=False)
    CSAT_evaluator = 'Enable' if select_csat_evaluator else 'Disable'
    #print('CSAT_evaluator: ', CSAT_evaluator)

    st.success(f"Connected to {modelName}", icon="ğŸ’š")
    clear_button = st.button("ëŒ€í™” ì´ˆê¸°í™”", key="clear")
    # print('clear_button: ', clear_but

st.title('ğŸ”® '+ mode)

if clear_button==True:
    chat.initiate()

# Preview the uploaded image in the sidebar
file_name = ""
if uploaded_file is not None and clear_button==False:
    print("uploaded_file.name: ", uploaded_file.name)
    print("CSAT_evaluator: ", CSAT_evaluator)

    if uploaded_file.name and CSAT_evaluator=="Disable":
        chat.initiate()

        if debugMode=='Enable':
            status = 'ì„ íƒí•œ íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.'
            print('status: ', status)
            st.info(status)

        file_name = uploaded_file.name
        file_url = chat.upload_to_s3(uploaded_file.getvalue(), file_name)
        print('file_url: ', file_url) 

        chat.sync_data_source()  # sync uploaded files
            
        status = f'ì„ íƒí•œ "{file_name}"ì˜ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤.'
        # my_bar = st.sidebar.progress(0, text=status)
        
        # for percent_complete in range(100):
        #     time.sleep(0.2)
        #     my_bar.progress(percent_complete + 1, text=status)
        if debugMode=='Enable':
            print('status: ', status)
            st.info(status)
    
        msg = chat.get_summary_of_uploaded_file(file_name, st)
        st.session_state.messages.append({"role": "assistant", "content": f"ì„ íƒí•œ ë¬¸ì„œ({file_name})ë¥¼ ìš”ì•½í•˜ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n\n{msg}"})    
        print('msg: ', msg)
        st.rerun()

    elif uploaded_file.name and CSAT_evaluator == "Enable" and uploaded_file.name.lower().endswith((".json")): # csv only   
        guide = "CSAT Evaluationì„ ì‹œì‘í•©ë‹ˆë‹¤."
        st.write(guide)
        st.session_state.messages.append({"role": "assistant", "content": guide})
        state_of_CSAT_evaluator = True

        chat.solve_CSAT_problem(uploaded_file.getvalue(), st)

# print("state_of_CSAT_evaluator: ", state_of_CSAT_evaluator)

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.greetings = False

# Display chat messages from history on app rerun
def display_chat_messages() -> None:
    """Print message history
    @returns None
    """
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

display_chat_messages()

def show_references(reference_docs):
    if debugMode == "Enable" and reference_docs:
        with st.expander(f"ë‹µë³€ì—ì„œ ì°¸ì¡°í•œ {len(reference_docs)}ê°œì˜ ë¬¸ì„œì…ë‹ˆë‹¤."):
            for i, doc in enumerate(reference_docs):
                st.markdown(f"**{doc.metadata['name']}**: {doc.page_content}")
                st.markdown("---")

# Greet user
if not st.session_state.greetings:
    with st.chat_message("assistant"):
        intro = "ì•„ë§ˆì¡´ ë² ë“œë½ì„ ì´ìš©í•˜ì—¬ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. í¸ì•ˆí•œ ëŒ€í™”ë¥¼ ì¦ê¸°ì‹¤ìˆ˜ ìˆìœ¼ë©°, íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìš”ì•½ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        st.markdown(intro)
        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": intro})
        st.session_state.greetings = True

if clear_button or "messages" not in st.session_state:
    st.session_state.messages = []        
    uploaded_file = None
    
    st.session_state.greetings = False
    st.rerun()

    chat.clear_chat_history()

if chart == 'Enable':
    if mode == 'Agent (Tool Use)':
        col1, col2, col3 = st.columns([0.1, 0.25, 0.1])
        url = "https://raw.githubusercontent.com/kyopark2014/agentic-workflow/main/contents/tool_use.png"
        col2.image(url)
    elif mode == 'Agent (Reflection)':
        col1, col2, col3 = st.columns([0.2, 0.3, 0.2])
        url = "https://raw.githubusercontent.com/kyopark2014/agentic-workflow/main/contents/reflection.png"
        col2.image(url)    
    elif mode == 'Agent (Planning)':
        col1, col2, col3 = st.columns([0.2, 0.3, 0.2])
        url = "https://raw.githubusercontent.com/kyopark2014/agentic-workflow/main/contents/planning.png"
        col2.image(url)
    elif mode == 'Agent (Multi-agent Collaboration)':
        col1, col2, col3 = st.columns([0.1, 2.0, 0.1])    
        url = "https://raw.githubusercontent.com/kyopark2014/agentic-workflow/main/contents/multi_agent_collaboration.png"
        col2.image(url)

# Always show the chat input
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”."):
    with st.chat_message("user"):  # display user message in chat message container
        st.markdown(prompt)

    st.session_state.messages.append({"role": "user", "content": prompt})  # add user message to chat history
    prompt = prompt.replace('"', "").replace("'", "")
    print('prompt: ', prompt)
    
    with st.chat_message("assistant"):
        if mode == 'ì¼ìƒì ì¸ ëŒ€í™”':
            stream = chat.general_conversation(prompt)
            response = st.write_stream(stream)
            print('response: ', response)
            st.session_state.messages.append({"role": "assistant", "content": response})
            # st.rerun()

            chat.save_chat_history(prompt, response)

        elif mode == 'RAG':
            with st.status("running...", expanded=True, state="running") as status:
                response, reference_docs = chat.run_rag_with_knowledge_base(prompt, st)                           
                st.write(response)
                print('response: ', response)

                st.session_state.messages.append({"role": "assistant", "content": response})
                if debugMode != "Enable":
                    st.rerun()

                chat.save_chat_history(prompt, response)
            
            show_references(reference_docs) 

        elif mode == 'Agent (Tool Use)':
            with st.status("thinking...", expanded=True, state="running") as status:
                response, reference_docs = chat.run_agent_executor(prompt, st)
                st.write(response)
                print('response: ', response)

                st.session_state.messages.append({"role": "assistant", "content": response})
                if debugMode != "Enable":
                    st.rerun()

                chat.save_chat_history(prompt, response)
            
            show_references(reference_docs) 
        
        elif mode == 'Agent (Reflection)':
            with st.status("thinking...", expanded=True, state="running") as status:
                # esponse, reference_docs = chat.run_knowledge_guru(prompt, st)
                response, reference_docs = chat.run_reflection(prompt, st)     
                st.write(response)
                print('response: ', response)

                if response.find('<thinking>') != -1:
                    print('Remove <thinking> tag.')
                    response = response[response.find('</thinking>')+12:]
                    print('response without tag: ', response)

                st.session_state.messages.append({"role": "assistant", "content": response})
                if debugMode != "Enable":
                    st.rerun()

                chat.save_chat_history(prompt, response)
            
            show_references(reference_docs) 

        elif mode == 'Agent (Planning)':
            with st.status("thinking...", expanded=True, state="running") as status:
                response, reference_docs = chat.run_planning(prompt, st)
                st.write(response)
                print('response: ', response)

                if response.find('<thinking>') != -1:
                    print('Remove <thinking> tag.')
                    response = response[response.find('</thinking>')+12:]
                    print('response without tag: ', response)

                st.session_state.messages.append({"role": "assistant", "content": response})
                if debugMode != "Enable":
                    st.rerun()

                chat.save_chat_history(prompt, response)
            
            show_references(reference_docs) 

        elif mode == 'Agent (Multi-agent Collaboration)':
            with st.status("thinking...", expanded=True, state="running") as status:
                response, reference_docs = chat.run_long_form_writing_agent(prompt, st)
                st.write(response)
                print('response: ', response)

                if response.find('<thinking>') != -1:
                    print('Remove <thinking> tag.')
                    response = response[response.find('</thinking>')+12:]
                    print('response without tag: ', response)

                st.session_state.messages.append({"role": "assistant", "content": response})
                if debugMode != "Enable":
                    st.rerun()

                chat.save_chat_history(prompt, response)
            
            show_references(reference_docs) 

        else:
            stream = chat.general_conversation(prompt)

            response = st.write_stream(stream)
            print('response: ', response)

            st.session_state.messages.append({"role": "assistant", "content": response})
            chat.save_chat_history(prompt, response)
        


